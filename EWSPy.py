# -*- coding: utf-8 -*-
"""
Created on Thu Feb 17 11:58:16 2022

@author: TEJan
"""

"""
EWS - Early Warning Signals
EWS Python functions (EWSPy)

@authors: KoenvanLoon & TijmenJanssen
"""

import numpy as np

import scipy.stats
from scipy import fft
from scipy.signal import convolve

from statsmodels.api import OLS
from statsmodels.tsa.ar_model import AutoReg

import warnings

import sys
sys.path.append("./pcrasterModules/")


# File name as string
"""
File name as string of abbreviation + time 

    ! - This function is tailored for names generated by EWS_pycatch_hourly/weekly.py . If your inputs are from a 
    different source file, you can name the files in the same manner or swap this function out.
    
Args:
-----

name : Abbreviation of the variable name, e.g. 'bioA' for biomass average and 'bioM' for biomass map (spatial data).

timestep : The timestep corresponding to the modelled time step at which the file was created, for average timeseries
    this always corresponds to the final timestep, whereas spatial data is saved at regular intervals defined in the
    configuration.
    
Returns:
--------

file_name_str : File name as a string as generated by the pycatch models, e.g. bioM0104.000 for biomass map 'bioM' at
    timestep 104000 .
    
"""


def temporal_sum(numpy_array):
    return np.nansum(numpy_array, axis=1)

def file_name_str(name, timestep):
    file_name_str = ["0"]*11
    name_list = list(name)
    timestep_list = reversed(str(timestep))
    for k, letter in enumerate(name_list):
        file_name_str[k] = letter
    for k, number in enumerate(timestep_list):
        file_name_str[-(k+1)] = number
    file_name_str.insert(-3, '.')
    file_name_str = [''.join(file_name_str)]
    return file_name_str[0]


# Generated number length
"""
Generates the number length used for folder-names where generated data is stored. 

Args:
-----

realizations : int, number of generated datasets made.

Returns:
-----

generated_number_length : int, number length used for folder-names where generated data is stored. Standard is 4,
    otherwise number length equals the maximum number of individual numbers used

"""


def generated_number_length(realizations):
    generated_number_length = 4
    if len(str(realizations)) > 4:
        generated_number_length = len(str(realizations))
    return generated_number_length


# Spatial early-warning signals
"""
Spatial methods included per phenomena

Rising memory :
    Spatial correlation : Moran's I

Rising variability :
    Spatial standard deviation 
    Spatial variance
    Spatial skewness
    
Other :
    Spatial kurtosis
    Power spectrum : Only works for square matrices - method not tested

"""

# Spatial mean
"""
Calculates the mean of 2D numpy arrays as found inside a 3D numpy array.

Args:
-----

numpy_matrix : A 3D numpy array representing the temporal evolution of spatial (2D) data.

Returns:
-----

* : A 2D numpy array with the spatial mean over time. Calculated using np.nanmean().

"""


def spatial_mean(numpy_matrix):
    # return np.array([np.nanmean(array) for array in numpy_matrix])
    return np.nanmean(numpy_matrix, axis=(1, 2))


# Spatial standard deviation
"""
Calculates the standard deviation of 2D numpy arrays as found inside a 3D numpy array.

Args:
-----

numpy_matrix : A 3D numpy array representing the temporal evolution of spatial (2D) data.

Returns:
-----

* : A 2D numpy array with the spatial standard deviation over time. Calculated using np.nanstd().

"""


def spatial_std(numpy_matrix):
    return np.nanstd(numpy_matrix, axis=(1, 2))


# Spatial variance
"""
Calculates the variance of 2D numpy arrays as found inside a 3D numpy array.

Args:
-----

numpy_matrix : A 3D numpy array representing the temporal evolution of spatial (2D) data.

Returns:
-----

* : A 2D numpy array with the spatial variance over time. Calculated using np.nanvar().

"""


def spatial_var(numpy_matrix):
    return np.nanvar(numpy_matrix, axis=(1, 2))


# Spatial skewness
"""
Calculates the skewness of 2D numpy arrays as found inside a 3D numpy array.

Args:
-----

numpy_matrix : A 3D numpy array representing the temporal evolution of spatial (2D) data.

Returns:
-----

* : A 2D numpy array with the spatial skewness over time. Calculated using scipy.stats.skew().

"""


def spatial_skw(numpy_matrix):
    return [scipy.stats.skew(np.nditer(array), nan_policy='omit') for array in numpy_matrix]


# Spatial kurtosis
"""
Calculates the kurtosis of 2D numpy arrays as found inside a 3D numpy array.

Args:
-----

numpy_matrix : A 3D numpy array representing the temporal evolution of spatial (2D) data.

Returns:
-----

* : A 2D numpy array with the spatial kurtosis over time. Calculated using scipy.stats.kurtosis().

"""


def spatial_krt(numpy_matrix):
    return [scipy.stats.kurtosis(np.nditer(array), nan_policy='omit') for array in numpy_matrix]


# Spatial correlation (Moran's I)
"""
Calculates the spatial correlation of 2D numpy arrays as found inside a 3D numpy array.

        N   sum_i( sum_j( w_i,j ( x_i - x_m ) ( x_j - x_m )
    I = - * -----------------------------------------------
        W               sum_i( x_i - x_m )^2
        
    Where :
        I : Moran's I, with -1 for perfect dispersion, 0 for perfect randomness, and 1 for perfect clustering
        N : Number of spatial units with (i,j)
        x : Variable of interest (e.g. biomass)
        x_m : The mean of x
        w_ij : A matrix of spatial weights
        W : The sum of all w_ij
        
    For spatial weights, the rook neighborhood is used. Hence, only the bordering spatial 'cells' are taken into
    consideration for calculating Moran's I. 

Args:
-----

numpy_matrix : A 3D numpy array representing the temporal evolution of spatial (2D) data.

Returns:
-----

* : A 2D numpy array with the spatial standard deviation over time. Calculated using Moran's I.

"""

rook_neighborhood = np.array([
    [0, 1, 0],
    [1, 0, 1],
    [0, 1, 0]
])

queen_neighborhood = np.array([
    [1, 1, 1],
    [1, 0, 1],
    [1, 1, 1]
])


def spatial_corr(numpy_matrix):  # Moran's I
    mean = spatial_mean(numpy_matrix)
    mean = np.nan_to_num(mean, nan=0)

    var = spatial_var(numpy_matrix)
    var = np.nan_to_num(var, nan=0)

    numpy_matrix_mmean = np.copy(numpy_matrix)
    numpy_matrix_mmean -= mean[:, None, None]

    is_nan = np.isnan(numpy_matrix_mmean)  # missing values in map are assumed to be np.NaN
    is_not_nan = ~ is_nan
    is_not_nan_as_nr = is_not_nan.astype(float)

    numpy_matrix_var = np.copy(is_not_nan_as_nr)
    numpy_matrix_var *= var[:, None, None]

    numpy_matrix_copy = np.copy(numpy_matrix)
    numpy_matrix_copy[is_nan] = 0

    sum_neighbours = convolve(numpy_matrix_copy, rook_neighborhood[None, :, :], mode='same')

    n_neighbours = convolve(is_not_nan_as_nr, rook_neighborhood[None, :, :], mode='same')
    n_neighbours_times_avg = convolve(is_not_nan_as_nr * mean[:, None, None], rook_neighborhood[None, :, :], mode='same')
    n_neighbours_times_avg[is_nan] = 0

    P1 = np.nansum(numpy_matrix_mmean * (sum_neighbours - n_neighbours_times_avg), axis=(1, 2))
    P2 = np.nansum(n_neighbours * numpy_matrix_var, axis=(1, 2))
    return P1 / P2


# def spatial_DFT(numpy_matrix):
#     return fft.fft2(numpy_matrix, axes=(-2,))
#
#
# def spatial_power_spec(numpy_matrix): # Only works for square matrices! Power spectrum as function of wave number (P(k))
#     n = numpy_matrix.shape[0]
#
#     fourier_image = fft.fft2(numpy_matrix) # fourier 'image'
#     fourier_amplitudes = np.abs(fourier_image) ** 2 # fourier amplitudes
#
#     kfreq = fft.fftfreq(n) * n # 1D array containing the wave vectors in k space
#     kfreq2D = np.meshgrid(kfreq, kfreq) # convertion to 2D array matching the layout of the fourier 'image'
#     knorm = np.sqrt(kfreq2D[0]**2 + kfreq2D[1]**2) # norm of wave vectors
#     knorm = knorm.flatten()
#     fourier_amplitudes = fourier_amplitudes.flatten()
#
#     kbins = np.arange(0.5, n//2 + 1, 1.) # start & end points of all bins
#     kvals = 0.5 * (kbins[1:] + kbins[:-1]) # corresponding k values
#
#     Abins, _, _ = scipy.stats.binned_statistic(knorm, fourier_amplitudes, statistic = "mean", bins = kbins) # average Fourier amplitude (**2) in each bin
#     Abins *= np.pi * (kbins[1:]**2 - kbins[:-1]**2) # total power --> multiply by area in each bin (eq5)
#
#     return fourier_image, kvals, Abins


# Temporal early-warning signals
"""
Temporal methods included per phenomena

Rising memory :
    Autocorrelation at lag 1
    Autoregressive coefficient of AR(1)
    Return rate : Inverse of AR(1) coefficient
    DFA : Detrended Fluctuation Analysis

Rising variability & flickering :
    Standard deviation
    Variance
    Coefficient of variation : standard deviation / mean
    Skewness
    Kurtosis
    Conditional heteroskedasticity

"""


# Temporal AR(1)
"""
Calculates the AR(1) parameters of a 1D array (window) inside a 2D array (stack of windows).

Args:
-----

stack_of_windows : A 2D numpy array containing a sliced timeseries (stack of windows).

Returns:
-----

AR1_params : Returns a 1D array containing the AR(1) parameter for each window calculated with 
    statsmodels.tsa_ar_model.AutoReg().

"""


def temporal_AR1(stack_of_windows):
    mean = temporal_mean(stack_of_windows)
    mean = np.nan_to_num(mean, nan=0.0)

    stack_of_windows_mmean = np.copy(stack_of_windows)
    stack_of_windows_mmean -= mean[:, None]

    AR1_params = []
    for numpy_array in stack_of_windows_mmean:
        mod = AutoReg(numpy_array, 1, trend='n').fit()
        AR1_params = np.append(AR1_params, mod.params)
    return AR1_params


# Temporal return rate
"""
Calculates the returnrate of a 1D array (window) inside a 2D array (stack of windows).

Args:
-----

stack_of_windows : A 2D numpy array containing a sliced timeseries (stack of windows).

Returns:
-----

* : Returns a 1D array containing the inverse of the AR(1) parameter for each window calculated with 
    statsmodels.tsa_ar_model.AutoReg().

"""


def temporal_returnrate(stack_of_windows):
    return np.reciprocal(temporal_AR1(stack_of_windows))


# Temporal conditional heteroskedasticity
"""
Returns the F-value or the R-squared value with their associated p-value of the residuals of an AutoReg model fitted on
    a 1D array (window) inside a 2D array (stack of windows).

Args:
-----

stack_of_windows : A 2D numpy array containing a sliced timeseries (stack of windows).

method : Selects whether 'R-squared' or 'F-statistic' is used as test of significance on the AutoReg residuals. 

alpha : Only called upon when method=='R-squared'. Selects used p-value.

log_transform : Selects whether the data is log-transformed before calculation. Usually False

Returns:
-----

test_statistic : The value of 'R-squared' or 'F-statistic'

p_val : The p-value accompanying the test_statistic

"""


def temporal_cond_het(stack_of_windows, method='R-squared', alpha=0.1, log_transform=False):
    if log_transform:
        stack_of_windows = np.log10(stack_of_windows)

    mean = temporal_mean(stack_of_windows)
    mean = np.nan_to_num(mean, nan=0.0)
    stack_of_windows_mmean = np.copy(stack_of_windows)
    stack_of_windows_mmean -= mean[:, None]

    test_statistic = []
    p_val = []
    for k, numpy_array in enumerate(stack_of_windows_mmean):
        ar_model = AutoReg(numpy_array, 1, trend='n').fit()
        ar_resid_sq = ar_model.resid**2
        lin_model = OLS(ar_resid_sq[1:], ar_resid_sq[:len(ar_resid_sq)-1]).fit()  # t+1 is dependent on t
        # If significant (p-value lower than given value), heteroscedasticity is present.
        if method == 'F-statistic':
            test_statistic = np.append(test_statistic, lin_model.fvalue)
            p_val = np.append(p_val, lin_model.f_pvalue)
        elif method == 'R-squared':
            test_statistic = np.append(test_statistic, lin_model.rsquared)
            p_val = np.append(p_val, scipy.stats.chi2.ppf((1 - alpha), df=1) / (len(ar_resid_sq)-1))
    return test_statistic, p_val


# Temporal autocorrelation
"""
Calculates the autocorrelation (correlation of a signal with a delayed copy of itself) at a specified lag of a 1D array 
    (window) inside a 2D array (stack of windows). 

Args:
-----

stack_of_windows : A 2D numpy array containing a sliced timeseries (stack of windows).

lag : Time lag, order. Usually set to 1

Returns:
-----

* : Returns a 1D array containing autocorrelation for a given lag for each window calculated by dividing the 
    autocovariance with the temporal variation.

"""


def temporal_autocorrelation(numpy_array, lag=1):
    return np.true_divide(temporal_autocovariance(numpy_array, lag=lag), temporal_var(numpy_array))


# Temporal autocovariance
"""
Calculates the autocovariance (the covariance3 of the process with itself at pairs of time points) of a 1D array 
    (window) inside a 2D array (stack of windows).

Args:
-----

stack_of_windows : A 2D numpy array containing a sliced timeseries (stack of windows).

lag : Time lag, order. Usually set to 1

Returns:
-----

* : Returns a 1D array containing value of autocovariance for each window calculated for the specified lag.

"""


def temporal_autocovariance(numpy_array, lag=1):
    auto_cov = [0.0] * len(numpy_array)
    for k, window in enumerate(numpy_array):
        N = len(window)
        mean = np.nanmean(window)
        mean = np.nan_to_num(mean, nan=0.0)

        end_padded_series = np.zeros(N+lag)
        end_padded_series[:N] = window - mean
        start_padded_series = np.zeros(N+lag)
        start_padded_series[lag:] = window - mean

        auto_cov[k] = np.sum(start_padded_series * end_padded_series) / N
    return auto_cov


# Temporal mean
"""
Calculates the mean of 1D numpy array (window) as found inside a 2D numpy array (stack of windows).

Args:
-----

numpy_array : A 2D numpy array containing a sliced timeseries (stack of windows).

Returns:
-----

* : A 1D numpy array with the temporal mean over time for each window. Calculated using np.nanmean().

"""


def temporal_mean(numpy_array):
    return np.nanmean(numpy_array, axis=1)


# Temporal standard deviation
"""
Calculates the standard deviation of 1D numpy array (window) as found inside a 2D numpy array (stack of windows).

Args:
-----

numpy_array : A 2D numpy array containing a sliced timeseries (stack of windows).

Returns:
-----

* : A 1D numpy array with the temporal standard deviation over time for each window. Calculated using np.nanstd().

"""


def temporal_std(numpy_array):
    return np.nanstd(numpy_array, axis=1)


# Temporal variance
"""
Calculates the variance of 1D numpy array (window) as found inside a 2D numpy array (stack of windows).

Args:
-----

numpy_array : A 2D numpy array containing a sliced timeseries (stack of windows).

Returns:
-----

* : A 1D numpy array with the temporal variance over time for each window. Calculated using np.nanvar().

"""


def temporal_var(numpy_array):
    return np.nanvar(numpy_array, axis=1)


# Temporal coefficient of variation
"""
Calculates the coefficient of variation of 1D numpy array (window) as found inside a 2D numpy array (stack of windows).

Args:
-----

numpy_array : A 2D numpy array containing a sliced timeseries (stack of windows).

Returns:
-----

* : A 1D numpy array with the temporal coefficient of variation over time for each window. Calculated by dividing the
    temporal standard deviation with the mean.

"""


def temporal_cv(numpy_array):
    return np.true_divide(temporal_std(numpy_array), temporal_mean(numpy_array))


# Temporal skewness
"""
Calculates the skewness of 1D numpy array (window) as found inside a 2D numpy array (stack of windows).

Args:
-----

numpy_array : A 2D numpy array containing a sliced timeseries (stack of windows).

Returns:
-----

* : A 1D numpy array with the temporal skewness over time for each window. Calculated using scipy.stats.skew().

"""


def temporal_skw(numpy_array):
    return scipy.stats.skew(numpy_array, axis=1, nan_policy='omit')


# Temporal kurtosis
"""
Calculates the kurtosis of 1D numpy array (window) as found inside a 2D numpy array (stack of windows).

Args:
-----

numpy_array : A 2D numpy array containing a sliced timeseries (stack of windows).

Returns:
-----

* : A 1D numpy array with the temporal kurtosis over time for each window. Calculated using scipy.stats.kurtosis().

"""


def temporal_krt(numpy_array):
    return scipy.stats.kurtosis(numpy_array, axis=1, nan_policy='omit')


# Divisor generator
"""
Calculates the scales over which fluctuations are calculated for Detrended Fluctuation Analysis (DFA). This function
    ensures that no remainders exist after division.

Args:
-----

lower_limit : The minimum amount of datapoints available for a scale used in DFA. Usually set to 10.

upper_limit : The maximum amount of datapoints available for a scale used in DFA. Usually equal to the window size.

Returns:
-----

* : A 1D numpy array with sorted scales.

"""


def divisor_generator(lower_limit, upper_limit):
    list = []
    for i in range(1, int(np.sqrt(upper_limit) + 1)):
        if (upper_limit % i == 0):
            if (upper_limit / i == i):
                list.append(i)
            else:
                list.append(i)
                list.append(upper_limit // i)

    sorted_list = sorted(list)
    return np.array([x for x in sorted_list if x >= lower_limit])


# Windowed Root Mean Square (RMS) with linear detrending
"""
Calculates the mean of 1D numpy array (window) as found inside a 2D numpy array (stack of windows).

Args:
-----

numpy_array : A 1D numpy array containing a window from a sliced timeseries (stack of windows).

scale : The number of datapoints in each segment into which the window is divided.

Returns:
-----

rms : A 1D numpy array with the quadratic mean for each scale (segment) of a given window.

"""


def calc_rms(numpy_array, scale):
    # Making of an array with data divided into segments
    shape = (numpy_array.shape[0] // scale, scale)
    segments = np.array([numpy_array[i:i + scale] for i in range(0, len(numpy_array), scale)]).reshape(shape)

    # Vector of x-axis
    scale_ax = np.arange(scale)
    rms = np.zeros(segments.shape[0])
    for i, segment in enumerate(segments):
        coeff = np.polyfit(scale_ax, segment, 1)
        xfit = np.polyval(coeff, scale_ax)
        # Detrending & computing RMS of each window
        rms[i] = np.sqrt(np.nanmean((segment - xfit)**2))
    return rms


# Detrended Fluctuation Analysis Propagator
"""
Calculates the propagator used for Detrended Fluctuation Analysis (DFA).

    ! - This is an empirical equation, and should be calibrated (polynomial regression) for *every* state variable 
    separately, which requires an AR(1) generated dataset based on the original dataset (see temporal null models).
    Furthermore, this adds all the assumptions of AR(1) as it translates the coefficient to the propagator (which is 
    assumed to be, but is not necessarily between 0 and 1) and can also introduce a certain error due to calibration 
    with (a non-optimal) polynomial regression.

Args:
-----

alpha : Polynomial coefficient taken as constant.

c_guess : Initial guess for c-value.

Returns:
-----

x1 : C-value after 5 iterations.

"""


def dfa_propagator(alpha, c_guess=0.5):
    # 0.91 * (c ** 3) - 0.37 * (c ** 2) + 0.49 * c + c - alpha = 0
    # a*x**3 + b*x**2 + c*x + d = 0.

    x1 = c_guess
    count = 0
    while count < 5:

        # if 0 < x1 <= 0.936:
        if x1 <= 0.936:
            a = 0.91
            b = - 0.37
            c = 0.49
            d = 0.52 - alpha

        elif 0.936 < x1 <= 0.967:
            a = 0
            b = -12.38
            c = 25.14
            d = 11.28 - alpha

        # elif 0.967 < x1 < 1:  # x1 can be greater than 1
        elif 0.967 < x1:
            a = 0
            b = 0
            c = 0.72
            d = 0.75 - alpha

        # Constructs the polynomial a*x**3 + b*x**2 + c*x + d
        poly = np.poly1d([a, b, c, d])
        roots = np.roots(poly)
        x1 = roots[-1].real

        count += 1

    return x1


# Temporal Detrended Fluctuation Analysis (DFA)
"""
Calculates the temporal detrended fluctuation analysis of 1D numpy array (window) as found inside a 2D numpy array 
    (stack of windows).

Args:
-----

stack_of_windows : A 2D numpy array containing a sliced timeseries (stack of windows).

Returns:
-----

scales : Scales used for DFA calculations. See Divisor generator

fluct : Fluctuations; the absolute mean of the root mean square. See calc_rms.

coeff : Coefficients of np.polyfit() for scales and fluctuations.

propagator : If not return_propagater; equal to coeff. Otherwise, dfa_propagator is used to calculate C-value 
    (see dfa_propagator).

"""


def temporal_dfa(stack_of_windows, window_size=100, return_propagator=False):
    fluct = []
    coeff = []
    scales = divisor_generator(10, window_size)
    propagator = []

    for numpy_array in stack_of_windows:
        # Cumulative sum of a single window with subtracted offset
        y = np.nancumsum(numpy_array - np.nanmean(numpy_array))  # noise like time series to random walk time series

        # RMS for each segment
        fluctuations = np.zeros(len(scales))  # a.ii.1
        for i, sc in enumerate(scales):
            fluctuations[i] = np.sqrt(np.mean(calc_rms(y, sc)**2))

        coefficients = np.polyfit(np.log2(scales), np.log2(fluctuations), 1)

        if return_propagator:
            propagator = np.append(propagator, dfa_propagator(coefficients[0]))

        fluct = np.append(fluct, fluctuations)
        coeff = np.append(coeff, coefficients[0])

    fluct = np.array_split(fluct, len(scales))

    if not return_propagator:
        propagator = coeff

    return scales, fluct, coeff, propagator


warnings.simplefilter('ignore', np.RankWarning)
# Ignore np.RankWarning (== the rank of the coefficient matrix in the least-squares fit is deficient)


"""
--------------------------------
# # # # Spatial methods # # # #
--------------------------------
Methods/indicators per phenomena
--------------------------------

Rising memory:
    Spatial correlation: Done & tested
    Return time*: NOT INCLUDED - Only applied in a single paper (Wissel, 1984), only mentioned by name in other works.
                                Furthermore, this return time (to equilibrium) is a function of time --> temporal
                                Or, it should be seen as return distance (spatial distance to mean state, bit vague)
    Discrete Fourier Transform (DFT): Done - Needs testing & conformation of method! -> how2plot?
Rising variability:
    Spatial variance: Done & tested
    Spatial skewness: Done & tested
Patchiness*:
    Spatial variance & skewness: Done & tested (as above)
    Patch-size distributions: NOT INCLUDED - Only relevant for biomass
    Regular spotted patterns: NOT INCLUDED - Only relevant for biomass
    Power spectrum: Done - Needs testing & conformation of method! -> only works for square matrices
    
*= not sure if necessary for this study
--------------------------------

--------------------------------
# # # # Temporal methods # # # #
--------------------------------
Methods/indicators per phenomena
--------------------------------
Rising memory:
    Autocorrelation lag 1: Done & tested
    Autoregressive coefficient of AR(1) model: Done - Needs testing & further improvements
    Return rate (inverse of AR(1) coefficient): Done - Needs testing & further improvements
    Detrended fluctuation analysis indicator: Done - Needs testing & further improvements
    Spectral density: TODO
    Spectral ratio (of low to high frequencies): TODO
    Spectral exponent: TODO
Rising variability & flickering:
    Standard deviation/variance: Done & tested
    Coefficient of variation: Done & tested
    Skewness: Done & tested
    Kurtosis: Done & tested
    Conditional heteroskedasticity: Done & tested
    BDS test**: TODO

*Models are not included, metrics are.
**= Can help to avoid false detections due to model misspecification.
***= alternative ways to measure autocorrelation lag-1
--------------------------------

"""